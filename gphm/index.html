<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>3D Gaussian Parametric Head Model's Project Page</title>
    <!-- Bootstrap -->
    <link href="css/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"> 
  </head>

  <!-- cover -->
  <section>
    <div class="jumbotron text-center mt-0">
      <div class="container">
        <div class="row">
          <div class="col-12">
            <h2 class="text-center">3D Gaussian Parametric Head Model</h2>
            <h4 style="color:#5a6268;">ECCV 2024</h4>
            <hr>
            <h6 class="text-center"><a href="https://yuelangx.github.io/">Yuelang Xu<sup>1</sup></a>, <a href="https://lizhenwangt.github.io/">Lizhen Wang<sup>1</sup></a>, <a href="https://zhengzerong.github.io/">Zerong Zheng<sup>2</sup></a>, <a href="https://suzhaoqi.github.io/">Zhaoqi Su<sup>1</sup></a>, <a href="http://www.liuyebin.com/">Yebin Liu<sup>1</sup></a></h6>
            <p class="text-center"><sup>1</sup>Tsinghua University  <sup>2</sup>NNKosmos Technology </p>
            <!-- <p> <a class="btn btn-secondary btn-lg" href="" role="button">Paper</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Code</a> 
                <a class="btn btn-secondary btn-lg" href="" role="button">Data</a> </p> -->

            <div class="row justify-content-center">
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                  <i class="fa fa-file"></i> ArXiv</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                    <i class="fa fa-file"></i> Paper</a> </p>
              </div>
              <div class="column">
                <p class="mb-5"><a class="btn btn-large btn-light" href="" role="button"  target="_blank">
                  <i class="fa fa-youtube"></i> Video</a> </p>
              </div>
              <div class="column">
                  <p class="mb-5"><a class="btn btn-large btn-light" href="https://github.com/YuelangX/3DGPHM" role="button"  target="_blank">
                    <i class="fa fa-github"></i> Code</a> </p>
              </div>
            </div>
            
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- abstract -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
          <h3>Abstract</h3>
              <!-- <br><br> -->
          <p class="text-left"> Creating high-fidelity 3D human head avatars is crucial for applications in VR/AR, telepresence, digital human interfaces, and film production. 
            Recent advances have leveraged morphable face models to generate animated head avatars from easily accessible data, representing varying identities and expressions within a low-dimensional parametric space. 
            However, existing methods often struggle with modeling complex appearance details, e.g., hairstyles and accessories, and suffer from low rendering quality and efficiency. 
            This paper introduces a novel approach, 3D Gaussian Parametric Head Model, which employs 3D Gaussians to accurately represent the complexities of the human head, allowing precise control over both identity and expression. 
            Additionally, it enables seamless face portrait interpolation and the reconstruction of detailed head avatars from a single image. Unlike previous methods, the Gaussian model can handle intricate details, enabling realistic representations of varying appearances and complex expressions. 
            Furthermore, this paper presents a well-designed training framework to ensure smooth convergence, providing a robust guarantee for learning the rich content. 
            Our method achieves high-quality, photo-realistic rendering with real-time efficiency, making it a valuable contribution to the field of parametric head models.
            </p>
            <p class="text-left">&nbsp;</p>
            <img src="assets/teaser.jpg" width="1080" alt="">
            <p class="text-left">Fig 1. We utilize hybrid datasets comprising captured multi-view video data and rendered image data from 3D scans for training our model. The trained model can be manipulated using decoupled identity and expression codes to produce a diverse array of high-fidelity head models. When presented with an image, our model can be adjusted to reconstruct the portrait in the image and edit the expression according to any other desired expressions.</p>
            <p>&nbsp;</p>
            <hr>
        </div>
      </div>
    </div>
  </section>
  <br>

  <section>
    <div class="container">
      <div class="row">
          <div class="col-12 text-center">
            <h3>Method</h3>
            <img src="assets/method.jpg" width="1080" alt="">
            <p class="text-left">Fig 2. &nbsp;Overview of 3D Gaussian Parametric Head Model.
              The pipeline of our method. Our training strategy can be divided into a Guiding Geometry Model for initialization, and a final 3D Gaussian Parametric Head Model. Deformations of each model are further decoupled into identity-related and expression-related deformations. Rendering involves using DMTet to transform the initial model into a mesh and 3D Gaussian Splatting for the Gaussian model. Features from both models are finally upsampled to high-resolution portrait images through a convolutional network $\boldsymbol{\Psi}$. During inference, our output exclusively comes from the Gaussian model.</p>
            <p>&nbsp;</p>
            <hr>
          </div>
        </div>

        <div class="row">
            <div class="col-12 text-center">
              <video width="1080" height=""  muted autoplay="autoplay" loop="loop">
                <source src="assets/id_interp.mp4" type="video/mp4">
              </video>
            </div>
          </div>
          
        <div class="row">
            <div class="col-12 text-center">
              <video width="1080" height=""  muted autoplay="autoplay" loop="loop">
                <source src="assets/exp_interp.mp4" type="video/mp4">
              </video>
            </div>
          </div>


        <div class="row">
            <div class="col-12 text-center">
              <video width="1080" height=""  muted autoplay="autoplay" loop="loop">
                <source src="assets/image_fitting.mp4" type="video/mp4">
              </video>
            </div>
          </div>

        <div class="row">
            <div class="col-12 text-center">
              <video width="1080" height=""  muted autoplay="autoplay" loop="loop">
                <source src="assets/exp_editting.mp4" type="video/mp4">
              </video>
            </div>
          </div>

      </div>
  </section>

  <!-- overview video -->
  <section>
    <div class="container">
      <div class="row">
        <div class="col-12 text-center">
            <h3>Demo Video</h3>
              <video width="1080" height=""  muted autoplay="autoplay" loop="loop">
                <source src="assets/video.mp4" type="video/mp4">
              </video>
            <hr>
        </div>
      </div>
    </div>
  </section>
  <br>

  <!-- citing -->
  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Citation</h3>
              <pre style="background-color: #e9eeef;padding: 1.25em 1.5em">
              <code>@inproceedings{xu2023gphm,
                title={3D Gaussian Parametric Head Model},
                author={Xu, Yuelang and Wang, Lizhen and Zheng, Zerong and Su, Zhaoqi and Liu, Yebin},
                booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
                year={2024}
              }</code></pre>
          <hr>
      </div>
    </div>
  </div>


  <div class="container">
    <div class="row ">
      <div class="col-12">
          <h3>Reference</h3>
          <p class="text-left">
            HeadNeRF: <em>Hong, Yang and Peng, Bo and Xiao, Haiyao and Liu, Ligang and Zhang, Juyong.
            HeadNeRF: A Real-Time NeRF-Based Parametric Head Model.
            Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022</em>
          </p>
          <p class="text-left">
            MoFaNeRF: <em>Zhuang, Yiyu and Zhu, Hao and Sun, Xusen and Cao, Xun. 
            MoFaNeRF: Morphable Facial Neural Radiance Field.
            Proceedings of the European Conference on Computer Vision (ECCV), 2022.</em>
          </p>
          <p class="text-left">
            PanoHead: <em>An, Sizhe and Xu, Hongyi and Shi, Yichun and Song, Guoxian and Ogras, Umit Y. and Luo, Linjie. 
            PanoHead: Geometry-Aware 3D Full-Head Synthesis in 360deg.
            Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023.</em>
          </p>
          <hr>
      </div>
    </div>
  </div>

</body>
</html>
